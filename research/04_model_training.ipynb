{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf491a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6022be68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lakshitjain/Developer/ML Projects/Brain-Tumor-MRI-Classification'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21b406d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir : Path\n",
    "    trained_model_path:Path\n",
    "    base_model_path:Path\n",
    "    training_data:Path\n",
    "    param_epochs : int\n",
    "    param_batch_size : int\n",
    "    param_is_augmentation : bool\n",
    "    param_image_size : list\n",
    "    param_learning_rate : float\n",
    "    param_seed : int\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir: Path\n",
    "    checkpoint_model_filepath: Path\n",
    "    tensorboard_root_log_dir: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27be82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainTumorMRIClassification.constants import *\n",
    "from brainTumorMRIClassification.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf\n",
    "from brainTumorMRIClassification import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa906ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath = CONFIG_FILE_PATH,params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_prepare_callbacks_config(self) -> PrepareCallbacksConfig:\n",
    "        config=self.config.prepare_callbacks\n",
    "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
    "        create_directories([Path(model_ckpt_dir), Path(config.tensorboard_root_log_dir)])\n",
    "        \n",
    "        return PrepareCallbacksConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            checkpoint_model_filepath=Path(config.checkpoint_model_filepath),\n",
    "            tensorboard_root_log_dir=Path(config.tensorboard_root_log_dir)\n",
    "        )\n",
    "    \n",
    "    def get_training_config(self)->TrainingConfig:\n",
    "        training=self.config.training\n",
    "        prepare_base_model=self.config.prepare_base_model\n",
    "        params=self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir)\n",
    "        create_directories([Path(training.root_dir)])\n",
    "\n",
    "        return TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            base_model_path=Path(prepare_base_model.base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            param_epochs=params.EPOCHS,\n",
    "            param_batch_size=params.BATCH_SIZE,\n",
    "            param_is_augmentation=params.AUGMENTATION,\n",
    "            param_image_size=params.IMAGE_SIZE,\n",
    "            param_learning_rate=params.LEARNING_RATE,\n",
    "            param_seed=params.SEED\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55b8a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PrepareCallback:\n",
    "    def __init__(self, config: PrepareCallbacksConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _create_early_stopping(self):\n",
    "        return tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='loss',\n",
    "            min_delta=1e-9,\n",
    "            patience=8,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def _create_reduce_lr(self):\n",
    "        return tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.3,\n",
    "            patience=5,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    def get_all_callbacks(self):\n",
    "        return [\n",
    "            self._create_early_stopping,\n",
    "            self._create_reduce_lr\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1dc7e787",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.base_model_path\n",
    "        )\n",
    "        self.model.compile(\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=self.config.param_learning_rate, beta_1=0.869, beta_2=0.995),\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "        train_dir = os.path.join(self.config.training_data, \"Training\")\n",
    "        test_dir = os.path.join(self.config.training_data, \"Testing\")\n",
    "        image_size = self.config.param_image_size\n",
    "        target_size = tuple(image_size[:2])  # Only height and width for flow_from_directory\n",
    "        batch_size = self.config.param_batch_size\n",
    "        SEED = self.config.param_seed\n",
    "        from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "        # Data augmentation and preprocessing for training\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=10,\n",
    "            brightness_range=(0.85, 1.15),\n",
    "            width_shift_range=0.002,\n",
    "            height_shift_range=0.002,\n",
    "            shear_range=12.5,\n",
    "            zoom_range=0,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=False,\n",
    "            fill_mode=\"nearest\"\n",
    "        )\n",
    "        self.train_generator = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=target_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode=\"categorical\",\n",
    "            seed=SEED\n",
    "        )\n",
    "\n",
    "        # No augmentation for test data, just rescaling\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        self.valid_generator = test_datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=target_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode=\"categorical\",\n",
    "            shuffle=False,\n",
    "            seed=SEED\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "        logger.info(f\"Model saved at {path}\")\n",
    "\n",
    "    def train(self, callback_list: list):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        logger.info(\"Training Started\")\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.param_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_data=self.valid_generator,\n",
    "            validation_steps=self.validation_steps,\n",
    "            callbacks=callback_list\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac0c6d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 20:58:13,233] : INFO : common : YAML file config/config.yaml loaded successfully.\n",
      "[2025-08-24 20:58:13,244] : INFO : common : YAML file params.yaml loaded successfully.\n",
      "[2025-08-24 20:58:13,244] : INFO : common : YAML file params.yaml loaded successfully.\n",
      "[2025-08-24 20:58:13,250] : INFO : common : Created directory: artifacts\n",
      "[2025-08-24 20:58:13,255] : INFO : common : Created directory: artifacts/prepare_callbacks/checkpoint_dir\n",
      "[2025-08-24 20:58:13,255] : INFO : common : Created directory: artifacts/prepare_callbacks/tensorboard_log_dir\n",
      "[2025-08-24 20:58:13,250] : INFO : common : Created directory: artifacts\n",
      "[2025-08-24 20:58:13,255] : INFO : common : Created directory: artifacts/prepare_callbacks/checkpoint_dir\n",
      "[2025-08-24 20:58:13,255] : INFO : common : Created directory: artifacts/prepare_callbacks/tensorboard_log_dir\n",
      "[2025-08-24 20:58:13,262] : INFO : common : Created directory: artifacts/training\n",
      "[2025-08-24 20:58:13,262] : INFO : common : Created directory: artifacts/training\n",
      "[2025-08-24 20:58:13,762] : WARNING : saving_utils : Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "[2025-08-24 20:58:13,762] : WARNING : saving_utils : Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Found 5712 images belonging to 4 classes.\n",
      "Found 5712 images belonging to 4 classes.\n",
      "Found 1311 images belonging to 4 classes.\n",
      "Found 1311 images belonging to 4 classes.\n",
      "[2025-08-24 20:58:13,942] : INFO : 763540678 : Training Started\n",
      "[2025-08-24 20:58:13,942] : INFO : 763540678 : Training Started\n",
      "Epoch 1/40\n",
      "Epoch 1/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 164ms/step - accuracy: 0.6354 - loss: 0.8120 - val_accuracy: 0.7578 - val_loss: 0.6056 - learning_rate: 0.0010\n",
      "Epoch 2/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 164ms/step - accuracy: 0.6354 - loss: 0.8120 - val_accuracy: 0.7578 - val_loss: 0.6056 - learning_rate: 0.0010\n",
      "Epoch 2/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6875 - loss: 0.6273 - val_accuracy: 0.7469 - val_loss: 0.6245 - learning_rate: 0.0010\n",
      "Epoch 3/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6875 - loss: 0.6273 - val_accuracy: 0.7469 - val_loss: 0.6245 - learning_rate: 0.0010\n",
      "Epoch 3/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 142ms/step - accuracy: 0.7982 - loss: 0.4990 - val_accuracy: 0.8031 - val_loss: 0.4415 - learning_rate: 0.0010\n",
      "Epoch 4/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 142ms/step - accuracy: 0.7982 - loss: 0.4990 - val_accuracy: 0.8031 - val_loss: 0.4415 - learning_rate: 0.0010\n",
      "Epoch 4/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7812 - loss: 0.5815 - val_accuracy: 0.8094 - val_loss: 0.4629 - learning_rate: 0.0010\n",
      "Epoch 5/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7812 - loss: 0.5815 - val_accuracy: 0.8094 - val_loss: 0.4629 - learning_rate: 0.0010\n",
      "Epoch 5/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 142ms/step - accuracy: 0.8509 - loss: 0.3840 - val_accuracy: 0.8781 - val_loss: 0.3227 - learning_rate: 0.0010\n",
      "Epoch 6/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 142ms/step - accuracy: 0.8509 - loss: 0.3840 - val_accuracy: 0.8781 - val_loss: 0.3227 - learning_rate: 0.0010\n",
      "Epoch 6/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8750 - loss: 0.4673 - val_accuracy: 0.8828 - val_loss: 0.3307 - learning_rate: 0.0010\n",
      "Epoch 7/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8750 - loss: 0.4673 - val_accuracy: 0.8828 - val_loss: 0.3307 - learning_rate: 0.0010\n",
      "Epoch 7/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 154ms/step - accuracy: 0.8826 - loss: 0.3038 - val_accuracy: 0.8625 - val_loss: 0.3966 - learning_rate: 0.0010\n",
      "Epoch 8/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 154ms/step - accuracy: 0.8826 - loss: 0.3038 - val_accuracy: 0.8625 - val_loss: 0.3966 - learning_rate: 0.0010\n",
      "Epoch 8/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9375 - loss: 0.3193 - val_accuracy: 0.8609 - val_loss: 0.4003 - learning_rate: 0.0010\n",
      "Epoch 9/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9375 - loss: 0.3193 - val_accuracy: 0.8609 - val_loss: 0.4003 - learning_rate: 0.0010\n",
      "Epoch 9/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 148ms/step - accuracy: 0.9125 - loss: 0.2407 - val_accuracy: 0.8531 - val_loss: 0.4202 - learning_rate: 0.0010\n",
      "Epoch 10/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 148ms/step - accuracy: 0.9125 - loss: 0.2407 - val_accuracy: 0.8531 - val_loss: 0.4202 - learning_rate: 0.0010\n",
      "Epoch 10/40\n",
      "\u001b[1m  1/178\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 117ms/step - accuracy: 0.9375 - loss: 0.1432\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9375 - loss: 0.1432 - val_accuracy: 0.8547 - val_loss: 0.4032 - learning_rate: 0.0010\n",
      "Epoch 11/40\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9375 - loss: 0.1432 - val_accuracy: 0.8547 - val_loss: 0.4032 - learning_rate: 0.0010\n",
      "Epoch 11/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 158ms/step - accuracy: 0.9445 - loss: 0.1588 - val_accuracy: 0.9281 - val_loss: 0.2171 - learning_rate: 3.0000e-04\n",
      "Epoch 12/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 158ms/step - accuracy: 0.9445 - loss: 0.1588 - val_accuracy: 0.9281 - val_loss: 0.2171 - learning_rate: 3.0000e-04\n",
      "Epoch 12/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9375 - loss: 0.1171 - val_accuracy: 0.9234 - val_loss: 0.2164 - learning_rate: 3.0000e-04\n",
      "Epoch 13/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9375 - loss: 0.1171 - val_accuracy: 0.9234 - val_loss: 0.2164 - learning_rate: 3.0000e-04\n",
      "Epoch 13/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 219ms/step - accuracy: 0.9583 - loss: 0.1164 - val_accuracy: 0.9523 - val_loss: 0.1459 - learning_rate: 3.0000e-04\n",
      "Epoch 14/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 219ms/step - accuracy: 0.9583 - loss: 0.1164 - val_accuracy: 0.9523 - val_loss: 0.1459 - learning_rate: 3.0000e-04\n",
      "Epoch 14/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9062 - loss: 0.2432 - val_accuracy: 0.9508 - val_loss: 0.1500 - learning_rate: 3.0000e-04\n",
      "Epoch 15/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9062 - loss: 0.2432 - val_accuracy: 0.9508 - val_loss: 0.1500 - learning_rate: 3.0000e-04\n",
      "Epoch 15/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 221ms/step - accuracy: 0.9634 - loss: 0.1023 - val_accuracy: 0.9469 - val_loss: 0.1401 - learning_rate: 3.0000e-04\n",
      "Epoch 16/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 221ms/step - accuracy: 0.9634 - loss: 0.1023 - val_accuracy: 0.9469 - val_loss: 0.1401 - learning_rate: 3.0000e-04\n",
      "Epoch 16/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 0.9438 - val_loss: 0.1489 - learning_rate: 3.0000e-04\n",
      "Epoch 17/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 0.9438 - val_loss: 0.1489 - learning_rate: 3.0000e-04\n",
      "Epoch 17/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 213ms/step - accuracy: 0.9692 - loss: 0.0873 - val_accuracy: 0.9578 - val_loss: 0.1151 - learning_rate: 3.0000e-04\n",
      "Epoch 18/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 213ms/step - accuracy: 0.9692 - loss: 0.0873 - val_accuracy: 0.9578 - val_loss: 0.1151 - learning_rate: 3.0000e-04\n",
      "Epoch 18/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9688 - loss: 0.0902 - val_accuracy: 0.9609 - val_loss: 0.1119 - learning_rate: 3.0000e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9688 - loss: 0.0902 - val_accuracy: 0.9609 - val_loss: 0.1119 - learning_rate: 3.0000e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 225ms/step - accuracy: 0.9743 - loss: 0.0768 - val_accuracy: 0.9516 - val_loss: 0.1284 - learning_rate: 3.0000e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 225ms/step - accuracy: 0.9743 - loss: 0.0768 - val_accuracy: 0.9516 - val_loss: 0.1284 - learning_rate: 3.0000e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9375 - loss: 0.1388 - val_accuracy: 0.9570 - val_loss: 0.1303 - learning_rate: 3.0000e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9375 - loss: 0.1388 - val_accuracy: 0.9570 - val_loss: 0.1303 - learning_rate: 3.0000e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 192ms/step - accuracy: 0.9771 - loss: 0.0680 - val_accuracy: 0.9625 - val_loss: 0.0919 - learning_rate: 3.0000e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 192ms/step - accuracy: 0.9771 - loss: 0.0680 - val_accuracy: 0.9625 - val_loss: 0.0919 - learning_rate: 3.0000e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9688 - loss: 0.0833 - val_accuracy: 0.9656 - val_loss: 0.0868 - learning_rate: 3.0000e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9688 - loss: 0.0833 - val_accuracy: 0.9656 - val_loss: 0.0868 - learning_rate: 3.0000e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 222ms/step - accuracy: 0.9762 - loss: 0.0622 - val_accuracy: 0.9734 - val_loss: 0.0747 - learning_rate: 3.0000e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 222ms/step - accuracy: 0.9762 - loss: 0.0622 - val_accuracy: 0.9734 - val_loss: 0.0747 - learning_rate: 3.0000e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9719 - val_loss: 0.0764 - learning_rate: 3.0000e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9719 - val_loss: 0.0764 - learning_rate: 3.0000e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 201ms/step - accuracy: 0.9775 - loss: 0.0655 - val_accuracy: 0.9625 - val_loss: 0.1007 - learning_rate: 3.0000e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 201ms/step - accuracy: 0.9775 - loss: 0.0655 - val_accuracy: 0.9625 - val_loss: 0.1007 - learning_rate: 3.0000e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9688 - loss: 0.0750 - val_accuracy: 0.9656 - val_loss: 0.0904 - learning_rate: 3.0000e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9688 - loss: 0.0750 - val_accuracy: 0.9656 - val_loss: 0.0904 - learning_rate: 3.0000e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 193ms/step - accuracy: 0.9836 - loss: 0.0525 - val_accuracy: 0.9555 - val_loss: 0.1264 - learning_rate: 3.0000e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 193ms/step - accuracy: 0.9836 - loss: 0.0525 - val_accuracy: 0.9555 - val_loss: 0.1264 - learning_rate: 3.0000e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m  1/178\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0066\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9633 - val_loss: 0.0972 - learning_rate: 3.0000e-04\n",
      "Epoch 29/40\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9633 - val_loss: 0.0972 - learning_rate: 3.0000e-04\n",
      "Epoch 29/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 213ms/step - accuracy: 0.9889 - loss: 0.0334 - val_accuracy: 0.9797 - val_loss: 0.0614 - learning_rate: 9.0000e-05\n",
      "Epoch 30/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 213ms/step - accuracy: 0.9889 - loss: 0.0334 - val_accuracy: 0.9797 - val_loss: 0.0614 - learning_rate: 9.0000e-05\n",
      "Epoch 30/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9688 - loss: 0.2249 - val_accuracy: 0.9797 - val_loss: 0.0597 - learning_rate: 9.0000e-05\n",
      "Epoch 31/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9688 - loss: 0.2249 - val_accuracy: 0.9797 - val_loss: 0.0597 - learning_rate: 9.0000e-05\n",
      "Epoch 31/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 223ms/step - accuracy: 0.9917 - loss: 0.0283 - val_accuracy: 0.9766 - val_loss: 0.0695 - learning_rate: 9.0000e-05\n",
      "Epoch 32/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 223ms/step - accuracy: 0.9917 - loss: 0.0283 - val_accuracy: 0.9766 - val_loss: 0.0695 - learning_rate: 9.0000e-05\n",
      "Epoch 32/40\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.9758 - val_loss: 0.0709 - learning_rate: 9.0000e-05\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.9758 - val_loss: 0.0709 - learning_rate: 9.0000e-05\n",
      "Epoch 32: early stopping\n",
      "Epoch 32: early stopping\n",
      "[2025-08-24 21:07:52,586] : WARNING : saving_api : You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "[2025-08-24 21:07:52,586] : WARNING : saving_api : You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "[2025-08-24 21:07:52,755] : INFO : 763540678 : Model saved at artifacts/training/brain_model.h5\n",
      "[2025-08-24 21:07:52,755] : INFO : 763540678 : Model saved at artifacts/training/brain_model.h5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config=ConfigurationManager()\n",
    "    prepare_callbacks_config=config.get_prepare_callbacks_config()\n",
    "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "    callbacks_list = prepare_callbacks.get_all_callbacks()\n",
    "\n",
    "    training_config=config.get_training_config()\n",
    "    training=Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train(callback_list=callbacks_list)\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ddbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
